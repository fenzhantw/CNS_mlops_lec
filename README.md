# CNS_mlops_lec
cns mlops

머신러닝 엔지니어링 강의:

MLops란 : 어떻게 효율적으로 머신러닝을 운영할지에 대한 방법론 및 방식

한재윤 책임님 

End2End로 서비스를 구현.
운영과 어떻게 최적화해서 올릴까?

M1. 머신러링 엔지니어링 이해하기

ML 엔지니어링이 왜 필요한가? 
- 비즈니스 문제 -> 목표 정의 -> 데이터 수집 및 전철 -> 피처 엔지니어링 -> 모델 학습 -> 모델 평가
DS의 업무는 학습한 모델을 평가하여 공유
분석가 + 컨설턴트 업무가 섞여 있는 경우가 많았음.

log-loss ->

DAP MLDL
:제품 수요를 사람의 경험에 의해 예측했지만, ML모델을 도입하여 장기간 예측을 더 빠르게 하고자 했음.

추천 결과를 개인화하고, 더 나아가 직무에 맞는 추천을 제공하길 원함. 
기존 규칙 기반의 추천 서비스를 ML기반을 둔 서비스로 탈바꿈하길 원함.

ML 모델 운영 반영

DS의 경우는 내 전문 영역은 이거니까, 이거만 하면 된다고 생각하는 경우가 많음. S/W 개발 프로세스에서 중요한 요소(Git, ERD, DB , CI/CD)
DS는 데이터를 요청하고 줄때까지 기다리고 있음 ->
DS는 모델 알고리즘 개발 뿐 아니라 개발한 모델이 시스템에서 잘 운영될 수 있도록 시스템 환경을 이해하고 mlops에 대해서도 알아야할 필요가 있다.

! DS + MLE !

담당에 통계를 잘하는 인원은 많고, 데이터 분석과 엔지니어링 둘 다 잘하는 사람은 없어서 고민이다. 둘 다 잘하는 사람들을 육성하고, 이런 역량을 가진 사람을 더 뽑고자 한다.
DA는 많고, 툴이 고도화 되면서 / 어떻게 고도화 시킬 수 있을까?

고객은 ML 모델을 운영시스템에 반영해주고
CNS는 MLops에 대한 이해를 바라고,
DS 조직은 엔지니어링도 잘하는 인력을 필요로 함.

엔지니어링 역량과 ML에서 확장되면서 Software Engineering 영역과 DevOps 역량으로 원함.
확장 영역. -> 사실은 훨씬 거대한 부분이기도 함.

본 강의에서는 ML Enginnering

엔지니어에게 중요한 것과 DS에게 중요한 것 

엔지니어에게 중요한 것 : 기술 스택과 도구들에 대해서 이해하고, 운영/ 유지보수를 고려한 환경 구성, 정형화된 개발 도구와 환경
개발 / 수정 반복에 대비한 코드 버전(git)
운영/유지보수를 고려한 환경 구성(QA, 운영 서버를 통한 서버 구성)

분석가가 확장된 업무 영역에 적응하기 위해 가져야할 엔지니어링 역량은?
지금처럼 분석가가 일하는데 필요한 도구와 방식을 사용하면서 엔지니어링처럼 정형화된 개발방식과 코드 버전 관리를 도입해 운영과 유지보수에 초점을 맞춘 모델 개발 문화를 지향해야함.

엔지니어링 정형화된 코드 관리와 운영 유지보수 
바뀌어가는 일하는 방식

기존에 데이터 분석 영역에서
모델 유지보수 / MLops 강의
기존 데이터 분석 영역은 SE 방식을 곁들이고, 그렇게 만든 모델을 MLops를 통해 운영 반영과 모니터링 수행.

내가 하고 싶은 것은 바로 기존 데이터 분석 영역 SE 방식을 곁들이고, 만든 모델을 MLops를 통해 운영 및 반영 모니터링 수행하는 일을 하고 싶다.

Why
제품 수요를 사람의 경험에 의해 예측했지만, ML을 

일 배치로 학습 이력을 학습하여 사용자마다 추천 결과를 생성함.
Gitlab을 구성하여 코드 버전 관리를 수행했고, 

MLE – DS 알고리즘을 상황에 맞게 
내가 가야할 구간은 ML Engineer와 DS의 겹치는 부분이라고 생각함.
ML 엔지니어와 MLops 직무를 생성하실 이유가 없지만, DS에서 훨씬 기술적이지만 테크니컬 한 영역임.
비즈니스 문제나 요구사항을 해결하는 것은 변함이 없음.

배포와 유지보수가 되어야 하기 때문에, 체계적인 개발 표준과 개발 도구 자동화 도구가 필요.

제가 나아가고자 하는 방향은 DS와 MLenginner이 합쳐진 것임.
그래서 결국 비즈니스 문제나 요구사항을 해결하는 것은 변함이 없음.
따라서, 저는 비즈니스 문제를 해결하기 위해 해당 프로젝트를 제안하였고, DS 처럼 일하였으며, 이를 ML engineering 처럼 구현하고자 했습니다.
저는 이 두가지가 합쳐야 한다고 생각하여서 저는 한 달동안 이렇게 일했습니다.

2. 
Clean code의 중요성: 
Code convention:
자산화한 코드를 봤는데, 변수명, 함수명이 잘 이해가 안됨.
빠르고 효율적인 유지보수 가능
->함수가 어떻게 작동하는지 알 수 없음.
코드 줄 바꿈이 이상하거나 너무 길게 작성되어 있음.
코드에 담긴 비즈니스 로직을 이해하기 어려움.

6page 클린코드: 빠르고 효율적인 유지보수 가능
클린 코드는 모든 팀원이 이해하도록 쉽도록 작성한 코드다. 클린 코드는 원저자가 아닌 다른 개발자가 읽고 개선할 수 있다.


클린코드의 규칙 : 코드 표준과 기본 설계 가이드를 준수할 것.
KISS 단순할수록 좋다 !
보이스카웃 규칙. 처음 봤을 때 보다 더 깔끔하게 만들 것.

PEP8: 파이썬을 개선하기 위해서 PEP8으로 관리함.
-	Style Guide for python code.
파이썬으로 코드를 작성할 때 지켜야 하는 규칙

Model.feature_importance_
끝에 언더바가 나오면 fitting하고 나서 나오는 것임. 그러한 convention임.
모듈 : 가능한 짧게 작성하고 소문자로만 작성해야함.
패키지 : 가능한 짧게 작성하고 소문자
패키지에는 가능한 짧게 작성하고 소문자로만 작성해야 함. E.g. sklearn 
Pip install scikit-learn
함수, 변수는 
클래스 : 파스칼 케이스를 사용함 RandomForestClassfier()
상수 모두 대문자로 작성함

PEP8 –(2) 코드 레이아웃
1)	코드의 모든 줄은 80글자를 넘지 않는다.
2)	모든 코드의 줄은 80자를 넘지 않음.
Rf = RandomForestClassfier(n_esitmar`~~~~~~~~~~~~~~~~~~~~~~~~~~~
RF = RandomFroestCals(n_eistiator,
				

최상위 레벨의 함수나 클래스 사이는 두 줄을 띄운다.
Class 안에 d는 메서드는 한 줄을 띄운다.

Def calculate_variance(number__list: List[float] ->float:


구현한 내용을 설명하기 어렵다면 나쁜 아이디어다.
불필요한 주석은 오히려 코드 줄 수만 늘릴 뿐, 도움이 되지 않음.
주석과 Docstring은 72자 제한을 가지며, 영어로 작성 시 항상 대문자로 시작함.
인라인 주석은 권장하지 않으며, 일반 블록 주석 (코드 옆에 작성하는 것 보다, 위에 적는다)
Docstring : google, numpy 스타일을 많이 사용함. 
_summary_

Args:

Raises:
Returns:
따옴표와 공백 : 작은따옴표와 큰따움표 모두 같은 역할이지만, 둘 중 한 가지만 사용한다.
“”\Hello, World\”

따옴표와 공백 (이항 연산자 앞 뒤로 반드시 공백을 추가한다)”

불필요한 공백은 사용하지 않음.

Import 순서:


Standard libraries
Import os
Import re
Import sys

Third part libraries
Import numpy as np

Local applications

변수 선언, 함수 작성 시 타입 힌팅을 통해 유지보수 가능한 코드를 작성할 수 있음.
	프로그램 안정성이 낮아질 수 있음. 

Code Convention 도구
정적 분석 도구
정적 분석이라는 것은 소스 코드의 실행 없이 정적으로 프로그램의 문제를 찾는 과정을 의미함.
Black, isort, mypy.
Black : 최근 가장 널리 쓰이는 Python 포맷터
PEP8로 정해진 코드 레이아웃을 그대로 따르게 함.
Pip install black
Pip install black[jupyter]
Mypy : 타입 체크를 위한 도구
어떤 함수가 문자열을 받아 문자열을 반환하는지? 체크
Git


Why git?
정적분석 도구를 사용해서 코드를 보기 쉽게 작성했는데, 코드를 더 효율적으로 관리는 어떻게 할 수 있을까요?
실제 최종 버전이 언제 어떻게 변했는지 추적하기 어려움.
최종 과정까지의 코드 히스토리를 관리할 수 있음. (특정 시점)으로 타임머신 타듯 돌아갈 수 있음.
Git은 프로그램임. -> 이에 대한 플랫폼이 github / gitlab / bitbucket 등이 있음.
대부분의 open source가 github에 있음 
Gitlab은 open source라서 커스텀이 쉽고, ci/cd가 간단함. 다양한 도구와 통합가능함.

Git clone을 많이 사용하는데, 실질적으로 git pull / git commit을 많이 씀.
Working diredctory라고 한다면 직접 작업하는 환경 ->파일을 변경하면 git add하면 변경사항을 적용시킴. Git add를 하면 변환되었다고 tranking만 하며 -> 임시적인 공간(staging area)로 감.
변경사항 확인했고, 정말 repository에 올려도 되겠네 라고하면 git commit을 하면 local repo로 됨. 
Working directory에 .git이 있고, git add와 git commit이 .git에 저장되어 있음. 그래서 wd는 실제로 안바뀜. 실제로 .git에 버전 별로 저장이 되어 있음. 언제 든지 예전 버전으로 돌아갈 수 있음. 그래서 git add해서 staging area -> commit -> local repository로 넘김. 
이후에 github으로 감. (내가 local에서 remote로 변경사항을 밀거야) git push
변경 사항을 다시 내 local로 끌고 올때는 git pull.
Git add 여러 번하고, git commit하여 (이정도면 변경사항에 저장해도 될 것 같다라고 생각하면 )local repo에 저장!
그러면 여러명에서 일할때?

36 page
각각의 변경사항이 있음. -> 각각을 remote로 해서 github에 올라갈것임. 
우리가 배포할 것은 master 저장소 -> 각각의 변경사항을 master로 땡겨줘. 라고 한다면 pull request임. 코드 리뷰가 끝나고 넘어가면 merge가 됨.
동시에 일하면 -> push -> Origin remote로 올라가게됨. -> pull request -> master remote로 올라감.
원격 저장소에 있는 것을 그대로 clone
Pull은 내가 이미 local repo가 있고, remote와 연결되어 있을 때 변경사항만 받는 것임.
Fetch는 변경 사항이 있는지 확인
Fork 복사를 할건데, clone과 다른 점은 원격에 저장됨 (origin 
Head는 마지막으로 작업한 위치가 head
Pull request -> repository에서 작업한 내용을 master에 merge 요청

Git 브랜칭 전략

작업 분기를 땀(branch)-> branch는 여러가지가 될 수 있음. 하나의 파일 base를 바탕으로 여러 사람이 작업을 할 수 있음. Branch 전략이 필요함. 하나의 저장소를 사용하는 환경에서 저장소를 잘하기 위해서 어떻게 할 수 있는지. 
Git flow 5가지 종류의 branch가 있음. 
Maser (최종적인 코드만 관리)
Develop 
Feature
Hotfix
Release
머신러닝은 master / devlop / feature 1 / feature 2 정도로 git branching 전략을 세우면 될 것 같음.
Develop branch와 feature branch로 작업하고, 코드 리뷰를 거치고 나서 다시 master로 합쳐짐.

Git repo를 만드는 것은 (remote repo)를 만드는것임. 이제 clone을 하여서 working directory로 만들어야함.


$ git log --graph --oneline
* a2f526a (HEAD -> main) hello, world!
* b48f580 (origin/main, origin/HEAD) Initial commit

Head는 내가 실행한 commit임 
그런데 여전히 origin/main은 initial commit을 바라보고 있음.
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

머신러닝 파이프라인:
ML 파이프라인
ML 파이프라인 개요 
ML 파이프라인 위한 환경 구성

머신러닝 파이프라인 정의
머신러닝 알고리즘을 둘러싼 인프라로, 프런트엔드에서 데이터를 수집하고, 학습 데이터를 파일에 넣고, 하나 이상의 모델을 학습시키고, 모델을 프로덕션으로 내보내는 작업.
데이터 추출, 데이터 전처리, 모델 학습, 모델 배포로 이어지는 모든 순서를 체계화하는 인프라로 설명함. 
파이프라인에서
기존 방식은 offline 데이터가 들어오면 수동적인 실험단계에서 평가하고 검증하고, 수동적인 과정에서 최종적으로 나오는 것은 모델 하나가 나오는 것임. 이 모델이 최종 산출물이됨.
그런데 우리가 모델을 만들 때, 쥬피터 노트북을 쓰면 내부는 JSON형식으로 되어 있어서, 
Jupyternotebook은 버전 관리가 매우 어려움. Git을 쓰는 이상 추적이 어려움.
머신러닝 파이프라인 방식은 Feature sotre() -> Code repository
->model을 Metadata storage에 저장 -> 모델에 문제가 생겼네 -> Train model이 끝이 아니기 때문에 다양한 모델을 구분하여 자동화 쉽고, 유지보수가 쉽지 않도록 진행함. 
세분화했기 때문에 변경 사항에 대한 추적이 빠름. 


환경을 구성할 때 가장 중요한 것은 모델을 잘 돌고, 개발 서버만 신경쓰면 안됨. 그래서 개발 서버에 있고 테스트 서버가 있고, QA서버가 있고, 운영 서버를 함. 
운영 이관을 해보면서, 어떤 버전을 썼었지?
판다스 1.10 버전을 써서 모델을 만듦.
나중에 판다스 2.0으로 시행했더니 다 무너짐. 라이브러리를 업데이트해서 운영이 무너질 수 있는 경우가 있음. 따라서 설치되어 있는 것을 어떻게든 관리를해서 잘 넘겨야함. 
그러한 의유로 의존성 문제로 환경 설정에 어려움을 겪음. 설치한 패키지를 어떤 방식으로 하나로 묶어서 미리 관리하고, 그 묶음을 그대로 다른 서버로 옮겨서 환경을 구성할 수 있음.
e.g, 분류 모델과 추천 알고리즘을 하나의 서버에서 개발해야 하는데..
설치할 분류 모델 패키지는 최근에 업데이트되어 numpy 최신 버전 사용만 가능함.
추천 알고리즘 패키지는 2년 전이 마지막 업데이트여서 과거의 numpy 버전 사용만 가능함.

전역 환경은 프로젝트의 모든 패키지와 의존성이 설치 및 관리되는 기본 환경 
기본 환경위에서 설치하면 모든 환경이 다 영향을 받음. 그 하위 환경에 다 영향을 받을 수 있음. 
의존성 충돌(dependency conflict)이 발생할 수 있음. 가상환경을 활용함 
전역 환경 아래에 독립적이고 격리된 가상환경을 만들 것임. 이는 다른 가상 환경에 전역 환경에 독립적인 환경이 되고, 각자가 각자에 영향을 미치지 않은 환경이 됨. 의존성 충돌없이 두 환경을 독립적으로 관리할 수 있음.

Scikit-learn 패키지도 설치 시 의존성 충돌을 방지하기 위해 독립된 가상 환경 사용을 적극 권장함. (strongly recommended)
가상환경에 대한 모티베이션이 생김 -> 어떤것을 쓰냐? Venv, virtualenv도 활용함. 너무 예전 것이라서 올드한 느낌이 있음.
최근에는 conda는 정말 많이 활용함. Commertial license이기 때문에 (mini conda)는 free임.
Pipenv
Pyenv -> 여러가지 파이썬 버전을 관리할 수 있는 툴임. 전역 환경에 python이 하나만 깔림. 그런것을 방지하기 위해 pyenv를 활용함. Miniconda는 한 번에 너무 많이 깔아둠.
Pipenv 라이브러리가 설치되어 있을 때, 의존성 문제까지 같이 관리를 해줌. 따라서, pipenv + pyenv를 함께 활용하면 의존성 관리를 할 수 있음.

Pyenv로 python을 설치하고, 그 버전 각각에 대해 pipenv를 활용해서 프로젝트를 관리함. Pipefile을 활용해서 의존성을 관리함.
Pipfile
Poetry / PDM -> PDM
PDM의 경우 버전을 자동으로 써줌.
프로젝트를 구조화 하고 ML 코드 모듈화 하고 
(1)	ML프로젝트 구조화
코드를 짤 때, 폴더 구조를 어떻게 하면 될까?
프로젝트 구조를 잘 만들어 놔야 프로젝트를 이해하고 분석하는데 잘 알 수 있음.
데이터 분석 프로젝트에서도 프로젝트 구조화 할 수 있음.

ML pipeline
데이터 수집 및 전처리
피처 엔지니어링
모델 학습
모델 평가
모델 배포
모델 서빙
모델 모니터링
Ml 프로젝트를 위한 폴더 자동화 툴 -> cookiecutter 
Cookiecutter를 삼아서 우리 구조를 가져가면 됨.
파이썬에서 모듈이라고 하면 함수나 변수를 모아둔 ~.py
각각의 기능을 독립적으로 분리하는 것을 모듈화라고 함. 
Table 따로, model 따로, 
분리하는 기준은 모델은 모델 마다 파일을 만들어 놓는 것이 가장 좋음. 
어떤 모델 수정해주세요는 어떤 모델.py로 들어가면 편하기 때문에 그것이 매우 편할 수 있음. 명명법에서 배운것처럼 클래스의 특성을 반영할 수 있도록 이름이 들어가야함. 최대한 파일 안에서 최소 기능에서 분리를 해야함. 전처리할때가 가장 중요함. 

전처리 => normalize, feature engineering  각자의 함수, 변수, 클래스는 최소 기능 별로 분리하여 작성(리팩토링) normalize 기능 수정해주세요. 찾기 편함.
모듈화를 해야 하는 이유는 유지보수를 잘 하기 위해서임. Log 찍는것은 거의 공통적으로 하는것임.
Helper function / logger function / validation function 등을 코드 재활용할 수 있음.
유지보수를 계속해야하는 프로젝트에서는 필수임. 최대한 모듈화를 해놓는 것이 좋다.
필요한 로직을 불러와서 메모리의 낭비를 줄일 수 있음. (from sklearn import *?) ㅋㅋ 모듈화를 안해놓으면 모든 코드에서 이런 식으로 다 불러와야함. 메모리도 엄청 뜨고, 기다리는 시간이 엄청 오래 걸림. 효율성이 떨어지게됨. 모듈화는 하면할수록 일도 조금 빠르게 할 수 있음. 이렇게 모듈화를 해놓으면 각 기능이 너무 세분화되어 있어서 테스트 코드를 작성하는 것이 매우 중요함.
소프트웨어 개발에서 테스트란 애플리케이션이 제대로 작동하는지 평가하고 검증하는 프로세스
(1)	단위 테스트(Unit Test) - (2) 통합테스트(Integration Test) (3) E2E 테스트 외부 시스템까지 해서 잘 작동하는지가 E2E 테스트해줌. 
(2)	테스트를 자동으로 생성되는 것이 존재함. (CodiumAI) 코드를 인식해서 자동으로 세부적인 단위 테스트까지 자동으로 만들어줌. 만약에 두개의 길이가 다르게 테스트도 할 수 있음.
분석가가 테스트가 어려운 것은 ML시스템은 사전에 명확하게 지정할 수 없는 데이터와 모델에 따라 크게 달라짐. ML-based system은 전통적인 모니터링과 다르게, prediction monitoring, system monitoring, data monitoring 등 다양한 테스트를 할 수 있음.

데이터 테스트 / 모니터링 테스트 / 모델 테스트


로그의 중요성 -> print는 휘발성임. 따라서 log를 찍는 것이 매우 중요함. 내가 만든 프로그램이 어떤식으로 돌아가고 있는지 파악하기 위해서 log를 찍는 것이 매우 중요함. 프로젝트에서 log 레벨 debug / info / warn / error 
debug에서 운영에서는 올라가지 않는 경우가 debug에서 설정됨. 두번째는 info임 실제 운영중인 프로그램일 운영에서도 내가 얻어야 하는 정보를 info 레벨에서 들어가게됨. / warn은 잠재적으로 문제가 될 수 있는 상태를 warning으로 찍게됨. Error는 심각한 오류나 예외 사항에 대해서 사용함. 

ML프로젝트르 ㄹ위한 로그 관리 – python 로그 모듈 구성 요소
logging이라는 모듈로 생성함. debug라는 단어가 들어가는 메시지 제외.
addFilter() 메서드로 추가 기능
log message - > logger -> filter ->formatter -> streamHandler / FileHandler

파이프라인 오케스트레이션 : 
-	데이터 수집 및 전처리 / 피처 엔지니어링 (Feature score)
-	모델 실험 관리
-	모델 배포/서빙
-	데이터 버저닝 -> 머신러닝 프로젝트는 같은 데이터를 넣었을 때, 똑 같은 결과를 뱉는 재현성임. 재현성 보장.
-	DAGsHub / DVC 데이터 버전 컨트롤.
-	Feast -> Feature Stroe : feature만 저장하는 것임. 모델에 사용하는 피처만 저장됨.
-	오프라인 피처와 온라인 피처(실시간 피처)를 모두 관리함.
-	Low latency를 유지할 수 있음 실시간 데이터에서 피처. 실시간 데이터와 오프라인 데이터의 시점을 맞춰주는 것. 
-	실시간 데이터 보다 배치성으로 돌아가는 데이터가 많음. 이러한 실시간 feature에 대한 니즈가 많이 업음
-	배차(카카오 택시, 우버) 등은 실시간으로 어디에 이동하고 있는지 파악해야 배차를 할 수 있고, 그런것을 관리를 해야 하면 실시간 데이터 -> 추천시스템
-	모델 실험 관리 -> DS가 가장 익숙함 (모델 아티팩트를 관리하고 모델 실험 결과를 관리함)
-	모델에 대한 모든 것. 모델 실험 관리가 가능한 도구는 배포/서빙이 포함하고 있는 것이 정말 많음. 모델 실험 성능이 가장 좋은 모델을 Model Registry에 등록하여 배포 /서빙 지원.
-	최종 모델에 endpoint를 이용해서 서빙을 해주는 도구. 배포와 서빙은 배포는 운영 서버에 올리는 모든 것. 배포는 end user까지 가는 것이.
-	운영 시스템에 올라가는 ML 파이프라인에서 가장 중요한 요소
-	굉장한 많은 모델 프레임워크를 지원할 수 있고, low latency로 결과를 전달할 수 있어야함 (online serving)
-	REST API를 손십게 만들 수 있는 기능을 지원 – Flask / 
-	서빙할때, 100ms 미만으로 내려가야함.(latency)가 낮아야함.
-	모델 모니터링과 유지보수 / Deepchecks / Great Expectations ml observability
-	우리가 리소스 모니터링 도구는 보통 Grafana / Prometheus를 사용함. ML 파이프라인에서 Stalenss를 확인 -> deepchecks를 추천함. 모델 결과에 대해서는 사용하기 어려운 것을 확인함. 모델 드리프트까지 확인함. 
-	Deepcheck를 돌렸을 때 나오는 리포트 페이지임. 굉장히 상세하게 내보내줌.
-	어디 integreation 해서 slack이나 teams에 공유가능. Deepcheck
-	파이프라인 오케스트레이션 툴 : 워크플로우를 이어주는 도구. 파이프라인 요소를 -> ML 파이프라인의 요소를 포함하는 오케스트레이션 도구도 있고, 다른 도구를 통합해야 하는 오케스트레이션 도구. Kubeflow / Airflow
-	MLDL이 없는게 모델 유지보수 / 모델 평가 툴 + 모니터링 없음 (drift)
-	Ray -> 파이썬의 멀티프로세싱 python – multi-processing -이론상 4배가 빨라짐. – 실제로 써보면 2배 언더로 빨라짐.
-	통신을 하면서 1-> 4core로 업무를 할당해줌. 하지만 파이썬은 통신의 메모리를 많이 먹음. 5GB - > multi processing -> 10GB가 됨. 통신 방식이 pickle 파일로 직렬화해서 옮김. 이론상으로 4배 빨라지는게 2배 미만으로 떨어짐. 그거에 대한 대안이 Ray임. 
-	Ray의 backend는 해당 통신 방식을 변경함. 4배라고 하면 3배 정도 나옴. 모델 실험 및 관리 쪽에 multi processing을 해주면 좋은 것 같음. -> Ray가 해당 부분에 파고듬. Ray Tune 멀티코어로 빠르게 tuning을 할 수 있음. -> 배포 및 서빙 또한 하기 시작함. 결론은 멀티 코어를 쓰기 위해서 Ray를 쓰면 좋음. 
-	기본적으로 모델 실험을 많이 하기 때문에 MLflow를 활용해서 실험 관리를 하며, ML 모델을 배포 및 서빙 할때는 BentomL / DeepChecks를 통해서 모니터링을 하게됨.
-	실시간 서빙을 위해 온라인 피처를 관리해야 할 때, Feast.
-	 
상황에 맞게 설계한 ml 파이프라인이 있으면, 자동으로 돌아가게 하는 것.
CI라는 것은 코드를 통합하는 것이며, mlops에서 모델의 검증과 테스트를 통합하는 의미
CD라는 것은 모델의 배포인데, 예측 서비스를 제공하는 모델임
CT는 지속적 학습 : MLops라는 워딩이며, 지속적으로 학습을 하고 리트레이닝을 하도록 만드는 것. 이런 식의 내용을 후속과정에서 

